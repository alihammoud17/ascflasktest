from nltk.tokenize import word_tokenize
# from tashaphyne.stemming import ArabicLightStemmer

# ArListem = ArabicLightStemmer()


def Tokeniz(text):
    return (word_tokenize(text))
